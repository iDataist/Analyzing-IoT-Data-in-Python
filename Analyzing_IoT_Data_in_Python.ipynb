{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing IoT Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Download data from URL\n",
    "res = requests.get(URL)\n",
    "\n",
    "# Convert the result\n",
    "data_temp = res.json()\n",
    "print(data_temp)\n",
    "\n",
    "# Convert json data to Dataframe\n",
    "df_temp = pd.DataFrame(data_temp)\n",
    "\n",
    "print(df_temp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire data with panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load URL to Dataframe\n",
    "df_temp = pd.read_json(URL)\n",
    "\n",
    "# Print first 5 rows\n",
    "print(df_temp.head())\n",
    "\n",
    "# Print datatypes\n",
    "print(df_temp.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load URL to Dataframe\n",
    "df_temp = pd.read_json(URL)\n",
    "\n",
    "# Save dataframe as json\n",
    "df_temp.to_json(\"temperature.json\", orient = 'records')\n",
    "\n",
    "# Save dataframe as csv\n",
    "df_temp.to_csv(\"temperature.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read file\n",
    "df_env = pd.read_csv(\"environmental.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# Print head\n",
    "print(df_env.head())\n",
    "\n",
    "# Print dataframe info\n",
    "print(df_env.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read file\n",
    "df_env = pd.read_json(\"environmental.json\")\n",
    "\n",
    "# Print head\n",
    "print(df_env.head())\n",
    "\n",
    "# Print dataframe info\n",
    "print(df_env.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read file from json\n",
    "df_env = pd.read_json(\"environmental.json\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(df_env.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MQTT single message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mqtt library\n",
    "import paho.mqtt.subscribe as subscribe\n",
    "\n",
    "# Retrieve one message\n",
    "msg = subscribe.simple(\"datacamp/iot/simple\", hostname=\"mqtt.datacamp.com\")\n",
    "\n",
    "# Print topic and payload\n",
    "print(f\"{msg.topic}, {msg.payload}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Datastream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to call by callback method\n",
    "def on_message(client, userdata, message):\n",
    "    # Parse the message.payload\n",
    "    data = json.loads(message.payload)\n",
    "    store.append(data)\n",
    "\n",
    "# Connect function to mqtt datastream\n",
    "subscribe.callback(on_message, topic, hostname=MQTT_HOST)\n",
    "\n",
    "df = pd.DataFrame(store)\n",
    "print(df.head())\n",
    "\n",
    "# Store DataFrame to csv, skipping the index\n",
    "df.to_csv(\"datastream.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing IoT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"temperature\", \"humidity\", \"pressure\"]\n",
    "\n",
    "# Create a line plot\n",
    "df[cols].plot(title=\"Environmental data\", secondary_y = 'pressure')\n",
    "\n",
    "# Label X-Axis\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"temperature\", \"humidity\", \"pressure\", \"radiation\"]\n",
    "\n",
    "# Create a histogram\n",
    "df[cols].hist(bins = 30)\n",
    "\n",
    "# Label Y-Axis\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print head of the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "# Drop missing rows\n",
    "data_clean = data.dropna()\n",
    "print(data_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print head of the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "# Forward-fill missing values\n",
    "data_clean = data.fillna(method = 'ffill')\n",
    "print(data_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print NA count\n",
    "print(data.isna().sum())\n",
    "\n",
    "# Resample data\n",
    "data_res = data.resample(\"10min\").last()\n",
    "\n",
    "# Calculate and print NA count\n",
    "print(data_res.isna().sum())\n",
    "\n",
    "# Plot the dataframe\n",
    "data_res.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Datastream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = []\n",
    "\n",
    "def on_message(client, userdata, message):\n",
    " \t# Combine timestamp and payload\n",
    "    data = f\"{message.timestamp},{message.payload}\"\n",
    "    # Append data to cache\n",
    "    cache.append(data)\n",
    "    # Check cache length\n",
    "    if len(cache) > MAX_CACHE:\n",
    "        with Path(\"energy.txt\").open(\"a\") as f:\n",
    "            # Save to file\n",
    "            f.writelines(cache)\n",
    "        # reset cache\n",
    "        cache.clear()\n",
    "\n",
    "# Connect function to mqtt datastream\n",
    "subscribe.callback(on_message, topics=\"datacamp/energy\", hostname=MQTT_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the timestamp\n",
    "df[\"ts\"] = pd.to_datetime(df[\"ts\"], unit = 'ms')\n",
    "\n",
    "# Print datatypes and first observations\n",
    "print(df.dtypes)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the timestamp with the parsed timestamp\n",
    "df['ts'] = pd.to_datetime(df[\"ts\"], unit=\"ms\")\n",
    "print(df.head())\n",
    "\n",
    "# Pivot the DataFrame\n",
    "df2 = pd.pivot_table(df, columns=\"device\", values=\"val\", index=\"ts\")\n",
    "print(df2.head())\n",
    "\n",
    "# Resample DataFrame to 1min\n",
    "df3 = df2.resample('1min').max().dropna()\n",
    "print(df3.head())\n",
    "\n",
    "df3.to_csv(TARGET_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Energy counter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample df to 30 minutes\n",
    "df_res = df.resample('30min').max()\n",
    "\n",
    "# Get difference between values\n",
    "df_diff = df_res.diff()\n",
    "\n",
    "# Get the percent changed\n",
    "df_pct = df_diff.pct_change()\n",
    "\n",
    "# Plot the DataFrame\n",
    "df_pct.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing IoT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "temperature.columns = [\"temperature\"]\n",
    "humidity.columns = [\"humidity\"]\n",
    "windspeed.columns = [\"windspeed\"]\n",
    "\n",
    "# Create list of dataframes\n",
    "df_list = [temperature, humidity, windspeed]\n",
    "\n",
    "# Concatenate files\n",
    "environment = pd.concat(df_list)\n",
    "\n",
    "# Print dataframe\n",
    "print(environment.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cmombine and resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes\n",
    "environ_traffic = pd.concat([environ, traffic], axis=1)\n",
    "\n",
    "# Print first 5 rows\n",
    "print(environ_traffic.head())\n",
    "\n",
    "# Create agg logic\n",
    "agg_dict = {\"temperature\": \"max\", \"humidity\": \"max\", \"sunshine\": \"sum\", \n",
    "            \"light_veh\": \"sum\", \"heavy_veh\": \"sum\",\n",
    "            }\n",
    "\n",
    "# Resample the dataframe \n",
    "environ_traffic_resampled = environ_traffic.resample('1h').agg(agg_dict)\n",
    "print(environ_traffic_resampled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation\n",
    "corr = data.corr()\n",
    "\n",
    "# Print correlation\n",
    "print(corr)\n",
    "\n",
    "# Create a heatmap\n",
    "sns.heatmap(corr, annot = True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a pairplot\n",
    "sns.pairplot(data)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean\n",
    "data[\"mean\"] = data['temperature'].mean()\n",
    "\n",
    "# Calculate upper and lower limits\n",
    "data[\"upper_limit\"] = data['mean'] + (3 * data['temperature'].std())\n",
    "data[\"lower_limit\"] = data['mean'] - (3 * data['temperature'].std())\n",
    "\n",
    "# Plot the dataframe\n",
    "data.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot traffic dataset\n",
    "traffic[:\"2018-11-10\"].plot()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Import tsaplots\n",
    "from statsmodels.graphics import tsaplots\n",
    "# Plot autocorrelation\n",
    "tsaplots.plot_acf(traffic['vehicles'], lags=50)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Perform decompositon \n",
    "res = sm.tsa.seasonal_decompose(traffic['vehicles'])\n",
    "\n",
    "# Print the seasonal component\n",
    "print(res.seasonal)\n",
    "\n",
    "# Plot the result\n",
    "res.plot()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal decomposition II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample dataframe to 1h\n",
    "df_seas = df.resample('1h').max()\n",
    "\n",
    "# Run seasonal decompose\n",
    "decomp = sm.tsa.seasonal_decompose(df_seas)\n",
    "\n",
    "# Plot the timeseries\n",
    "plt.title(\"Temperature\")\n",
    "plt.plot(df_seas['temperature'], label=\"temperature\")\n",
    "\n",
    "# Plot trend and seasonality\n",
    "plt.plot(decomp.trend[\"temperature\"], label=\"trend\")\n",
    "plt.plot(decomp.seasonal[\"temperature\"], label=\"seasonal\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning for IoT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_start_end(df):\n",
    "    return f\"from {df.iloc[0].name} to {df.iloc[-1].name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split day\n",
    "limit_day = \"2018-10-27\"\n",
    "\n",
    "# Split the data\n",
    "train_env = environment[:limit_day]\n",
    "test_env = environment[limit_day:]\n",
    "\n",
    "# Print start and end dates\n",
    "print(show_start_end(train_env))\n",
    "print(show_start_end(test_env))\n",
    "\n",
    "# Split the data into X and y\n",
    "X_train = train_env.drop(\"target\", axis = 1)\n",
    "y_train = train_env[\"target\"]\n",
    "X_test = test_env.drop(\"target\", axis = 1)\n",
    "y_test = test_env[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict classes\n",
    "print(logreg.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LogisticRegression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Score the model\n",
    "print(logreg.score(X_train, y_train))\n",
    "print(logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "sc.fit(environment)\n",
    "\n",
    "# Print mean and variance\n",
    "print(sc.mean_)\n",
    "print(sc.var_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "sc.fit(environment)\n",
    "\n",
    "# Transform the data\n",
    "environ_scaled = sc.transform(environment)\n",
    "\n",
    "# Convert scaled data to DataFrame\n",
    "environ_scaled = pd.DataFrame(environ_scaled, \n",
    "                              columns=environment.columns, \n",
    "                              index=environment.index)\n",
    "print(environ_scaled.head())\n",
    "plot_unscaled_scaled(environment, environ_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create Scaler and Regression objects\n",
    "sc = StandardScaler()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Create Pipeline\n",
    "pl = Pipeline([\n",
    "        (\"scale\", sc),\n",
    "        (\"logreg\", logreg)\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline and print predictions\n",
    "pl.fit(X_train, y_train)\n",
    "print(pl.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline\n",
    "pl = Pipeline([\n",
    "        (\"scale\", StandardScaler()),\n",
    "        (\"logreg\", LogisticRegression())\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Store the model\n",
    "with Path(\"pipeline.pkl\").open('bw') as f:\n",
    "\tpickle.dump(pl, f)\n",
    "  \n",
    "# Load the pipeline\n",
    "with Path(\"pipeline.pkl\").open('br') as f:\n",
    "\tpl_loaded = pickle.load(f)\n",
    "\n",
    "print(pl_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline\n",
    "pl = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "  \t\t('logreg', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Predict classes\n",
    "predictions = pl.predict(X_test)\n",
    "\n",
    "# Print results\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply model to data stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_subscribe(client, userdata, message):\n",
    "    data = json.loads(message.payload)\n",
    "    # Parse to DataFrame\n",
    "    df = pd.DataFrame.from_records([data], index=\"timestamp\", columns=cols)\n",
    "    # Predict result\n",
    "    category = pl.predict(df)\n",
    "    if category[0] < 1:\n",
    "        # Call business logic\n",
    "        close_window(df, category)\n",
    "    else:\n",
    "        print(\"Nice Weather, nothing to do.\")  \n",
    "\n",
    "# Subscribe model_subscribe to MQTT Topic\n",
    "subscribe.callback(model_subscribe, topic, hostname=MQTT_HOST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
